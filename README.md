# VQAsk
In this project we developed a Flutter application focused on the Visual Question Answering task, a computer vision task where a system is given a text-based question about an image, and it must infer the answer.
We have implemented different interaction modes to guarantee an enjoyable user experience and to give users the possibility to choose how to exploit the application's functionalities according to their needs or preferences.
Particularly, this application provides the following modalities:
- Voice Interaction
- Haptic Interaction
- Visual Interaction
  
This project has been developed during the A.Y. 2022-23 for the Multimodal Interaction course at Sapienza University of Rome.

## Some screen examples of the app
<img src="https://imgur.com/MHqG48J.png" width="300"> <img src="https://imgur.com/zFRPyEd.png" width="300"> <img src="https://imgur.com/Q4nZ9lf.png" width="300">

## Getting Started

To launch the application, type the command ```flutter run``` on the terminal after connecting a physical or emulated android device.

A few resources to get you started if this is your first Flutter project:

- [Lab: Write your first Flutter app](https://docs.flutter.dev/get-started/codelab)
- [Cookbook: Useful Flutter samples](https://docs.flutter.dev/cookbook)

For help getting started with Flutter development, view the
[online documentation](https://docs.flutter.dev/), which offers tutorials,
samples, guidance on mobile development, and a full API reference.

## Authors
- Chiara Giacanelli
- Clizia Giorgia Manganaro
- Alessio Palma
- Davide Santoro
